{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vkKRHMaGBwRn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "img_dir = '/tmp/nst/'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/d/d7/Green_Sea_Turtle_grazing_seagrass.jpg\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/0/00/Tuebingen_Neckarfront.jpg\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/6/68/Pillars_of_creation_2014_HST_WFC3-UVIS_full-res_denoised.jpg\n",
    "!wget --quiet -P /tmp/nst/ https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "#import cv2\n",
    "from scipy.signal import convolve\n",
    "from ipywidgets import interact, fixed\n",
    "content_path = '/tmp/nst/Green_Sea_Turtle_grazing_seagrass.jpg'\n",
    "style_path = '/tmp/nst/The_Great_Wave_off_Kanagawa.jpg'\n",
    "cube_path = 'cube.png'\n",
    "wheel_path = 'wheel.jpeg'\n",
    "turtle = mpimg.imread(content_path)\n",
    "wave = mpimg.imread(style_path)\n",
    "cube = mpimg.imread(cube_path) * 255\n",
    "wheel = mpimg.imread(wheel_path)\n",
    "white = mpimg.imread(\"white.jpg\")\n",
    "black = mpimg.imread(\"black.png\")\n",
    "def make_black_and_white(image):\n",
    "  return image @ (1/3,1/3,1/3)\n",
    "\n",
    "def show_image(image):\n",
    "  if image.ndim == 2:\n",
    "    _ = plt.imshow(image.astype('uint8'),cmap='Greys')\n",
    "  else:\n",
    "    _ = plt.imshow(image.astype('uint8'))\n",
    "\n",
    "  \n",
    "black_and_white_turtle = make_black_and_white(turtle).astype('uint8')\n",
    "\n",
    "def blur(image,size):\n",
    "  if len(image.shape) == 3:\n",
    "    return blur3d(image,size)\n",
    "  C = np.ones([size,size]) / (size**2)\n",
    "  return convolve(image,C)\n",
    "\n",
    "\n",
    "def blur3d(image,size):\n",
    "  A = []\n",
    "  for i in range(3):\n",
    "    channel = image[:,:,i]\n",
    "    A.append(blur(channel,size))\n",
    "  return np.dstack(A)\n",
    "\n",
    "def make_slider():\n",
    "    return widgets.FloatSlider(value=.5,min=0,max=1.0,step=.1)\n",
    "\n",
    "def channel(image,x,y,z):\n",
    "    return image * (x,y,z)\n",
    "\n",
    "def plot_channel(image,red,green,blue):\n",
    "    show_image(channel(image,red,green,blue))\n",
    "\n",
    "def interactive_channel(image):\n",
    "    interact(plot_channel,image = widgets.fixed(image), red = make_slider(),green=make_slider(),blue=make_slider())\n",
    "    \n",
    "def detect_edges(image):\n",
    "    if image.ndim == 3:\n",
    "        image = make_black_and_white(image)\n",
    "    \n",
    "def separate_image(image):\n",
    "    _=fig, ax = plt.subplots(2, 2, sharex='col', sharey='row',figsize=[8,8])\n",
    "    _=ax[0][0].imshow(image  * (1,1,1))\n",
    "    _=ax[0][1].imshow(image  * (1,0,0))\n",
    "    _=ax[1][0].imshow(image * (0,1,0))\n",
    "    _=ax[1][1].imshow(image * (0,0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1j3ez8KXySf2"
   },
   "source": [
    "Ignore everything before this line, it's not important to the lesson, but is needed to make everything else work. Before starting, go to the tab above that says **Runtime**, and then click on **Restart and Run All**. Please let me know if you have trouble.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4BwFSu0izlL"
   },
   "source": [
    "# Matrices in Real Life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHRQ3UCUiqfN"
   },
   "source": [
    "Matrices are a main way that computers store data. In this lesson, we will learn how computers use matrices to store images. Do not worry about how the code works, we are mainly interested in the math behind it! Feel free to ask me after class if you want to learn more about it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_iSLc2DQw2Kk"
   },
   "source": [
    "# Black and White Images\n",
    "\n",
    "A black and white image is just a matrix of values between 0-255.  Let $A$ be the image. $A_{ij}$ represents the intensity of the image at point $i,j$. 0 means black, 255 means white, and everything in between is gray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oZx35NHWyq3y",
    "outputId": "c7b9a0c6-d976-4951-9187-deba20bb07d4"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b0uNdrvryvCo"
   },
   "source": [
    "This means the image matrix has 2525 rows and 3367 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "iMsf5MhOxYLt",
    "outputId": "561e825f-a5bb-4ce3-faa8-e1261b6328b9"
   },
   "outputs": [],
   "source": [
    "black_and_white_turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "g4LfqFqExkQG",
    "outputId": "96f029ba-f2c4-4aa3-a5a7-f1e20629d855"
   },
   "outputs": [],
   "source": [
    "show_image(black_and_white_turtle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9ClRLrrxwrM"
   },
   "source": [
    "# Color \n",
    "\n",
    "But black and white images are boring! Instead of a matrix of numbers, color image is a matrix of length 3 vectors. $C_{ij} = (r,g,b)$ In fact, a color image can be separated into red, green, and blue components. Let's explore how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "g6GhE59By4cj",
    "outputId": "27f2adf5-f168-4bf0-bef0-5b7bfea6bacd"
   },
   "outputs": [],
   "source": [
    "separate_image(turtle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aN6txmxSy6Dh"
   },
   "source": [
    "The color version of turtle has 2525 rows, 3367 columns, and 3 channels (one for each color)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg6khVB5r7Uk"
   },
   "source": [
    "We can multiply all elements in each matrix in image by a number between 0-1.\n",
    "\n",
    "Let $v = (x,y,z)$.\n",
    "\n",
    "$C * v = (R*x, G*y, B*z)$\n",
    "\n",
    "The shape does not change, just the values. \n",
    "\n",
    "If $v=(1,1,1)$ we get just the original image. What do you think would happen if we change $v$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "Oftt5rg4H1h7",
    "outputId": "fb9cf694-6498-4f5b-b1b4-6f4eb674d960"
   },
   "outputs": [],
   "source": [
    "x,y,z = 1,1,1\n",
    "v = x,y,z\n",
    "show_image(turtle * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PTo_9LRLsdcH"
   },
   "source": [
    "Let's try making $y$ and $z$ smaller while keeping $x$ the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "WxBFwvpkH6F0",
    "outputId": "f9c2d1f4-bf17-46a0-fa68-ed817d0d6be9"
   },
   "outputs": [],
   "source": [
    "x,y,z=1,.5,.5\n",
    "v=x,y,z\n",
    "show_image(turtle*v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOi1D5rtsm5t"
   },
   "source": [
    "The image is now more red! What do you think would happen if we make one color 1, and the others 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "i4sttWJjXlNx",
    "outputId": "96fb6a1e-2b1f-4be2-b307-86da5e7ebe47"
   },
   "outputs": [],
   "source": [
    "x,y,z = 0,0,1\n",
    "v = x,y,z\n",
    "show_image(wave * v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrLtd3S0s1VU"
   },
   "source": [
    "The image is now completely blue! Now experiment with changing $x,y,z$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "aX3fNNxD96PD",
    "outputId": "d81d821c-e456-4774-8804-521faa7f37b9"
   },
   "outputs": [],
   "source": [
    "x,y,z = .9,2,.4\n",
    "v = x,y,z\n",
    "show_image(wave * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_channel(wheel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Seof56kdtHfq"
   },
   "source": [
    "# Make a Color Image Black and White\n",
    "\n",
    "A color image can be converted into a black and white one. To do this, we will multiply the matrix by the vector (1/3,1/3,1/3). This just takes the average value of the 3 channels. Note: \n",
    "\n",
    "```\n",
    "@\n",
    "``` means matrix multiplication in the code.\n",
    "\n",
    "Let $B$ be the Black and White version of image $A$.\n",
    "$$v = (1/3,1/3,1/3)$$\n",
    "$$\\implies B = C v^T = (1/3R + 1/3G + 1/3B)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1e4dgDwjIT5N"
   },
   "outputs": [],
   "source": [
    "black_and_white_wave = wave @ (1/3,1/3,1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "GS93hoPlIgiN",
    "outputId": "33f9f279-3176-479d-ab1f-83790b877b6f"
   },
   "outputs": [],
   "source": [
    "show_image(black_and_white_wave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTg3k0thzUUu"
   },
   "source": [
    "# Negative Images\n",
    "\n",
    "To make an image negative, we will want to reverse the value of each pixel.\n",
    "\n",
    "Let $N$ be the negative matrix. $N_{ijk} = 255 - A_{ijk}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "p778L39pzw73",
    "outputId": "d8b18614-5b38-44cd-f606-708b1c531aca"
   },
   "outputs": [],
   "source": [
    "show_image(255 - cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKExq5UfLDic"
   },
   "source": [
    "# For Fun: More Advanced Image Filters\n",
    "\n",
    "It's ok if you don't completely understand the math behind these filters, they are more complicated than the ones we have used so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8SNS1J6B05S"
   },
   "source": [
    "# Blurry Images\n",
    "To blur an image, we convolve a with another matrix. What this does is take the average of the pixels around it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UXlmIifWFZs0"
   },
   "source": [
    "It is hard to tell that a pixel is blurred at all when the size of the convolution matrix is only 10x10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "_0tbnl652Md3",
    "outputId": "00e046b6-4711-4338-c0c8-afce461b0121"
   },
   "outputs": [],
   "source": [
    "blurry_image = blur(image=turtle,size=10)\n",
    "show_image(blurry_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vu_O3finFi9s"
   },
   "source": [
    "When increased to 100x100, the image is very blurry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "6-lEKCYJBrah",
    "outputId": "cc4412ea-85cb-45d8-d2ec-6a7f7d2bc26b"
   },
   "outputs": [],
   "source": [
    "blurry_image = blur(image=wave,size=160)\n",
    "show_image(blurry_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVpaQGFTNWoo"
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged=np.clip(convolve(cube@(1/3,1/3,1/3),edge_matrix),a_min=0,a_max=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged=np.clip(convolve(cube@(1/3,1/3,1/3),edge_matrix),a_min=0,a_max=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(edged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGcv8MmhG_QF"
   },
   "source": [
    "# Why this matters\n",
    "\n",
    "Image processing techniques are of growing importance today. The field of using computers to understand image data is called Computer Vision. It is used in technologies including:\n",
    "\n",
    "\n",
    "*   Self driving cars\n",
    "*   Face Recognition\n",
    "*   Cancer detection\n",
    "*   Product Sorting\n",
    "*   Robotics\n",
    "\n",
    "A fun example of Computer Vision in action:\n",
    "\n",
    "https://www.youtube.com/watch?v=AboxUKxRYJw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIt6ZxzsDzih"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpXhbRWoD3rn"
   },
   "outputs": [],
   "source": [
    "def signal_handler(signal, frame):\n",
    "    # KeyboardInterrupt detected, exiting\n",
    "    global is_interrupted\n",
    "    is_interrupted = True\n",
    "    \n",
    "\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview = plt.imshow(frame)    \n",
    "else:\n",
    "    is_capturing = False\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "is_interrupted = False\n",
    "while is_capturing:\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview.set_data(frame)\n",
    "    plt.draw()\n",
    "\n",
    "    try:    # Avoids a NotImplementedError caused by `plt.pause`\n",
    "        plt.pause(0.05)\n",
    "    except Exception:\n",
    "        pass\n",
    "    if is_interrupted:\n",
    "        vc.release()\n",
    "        break    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvHH3h7UD4lV"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "cascPath = sys.argv[1]\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei1xCgE-D7MM"
   },
   "outputs": [],
   "source": [
    "cv2.CASCADE_SCALE_IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MathOfImages.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
